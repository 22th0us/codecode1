import tensorflow as tf # tensorflow를 tf로 import
import numpy as np # numpy를 np로 import

# set_random_seed를 이용해 random_seed를 초기화
tf.set_random_seed(0)  

# x_data는 입력 값, y_data는 출력 값
x_data = [1., 2., 3., 4.]
y_data = [1., 3., 5., 7.]

# random_normal -> 정규분포를 따르는 random number 1개 짜리를 tf.Variable을 W로 정의해서 W로 정의
W = tf.Variable(tf.random_normal([1], -100., 100.))

# for를 이용해서 gradient desent 부분을 300회 반복
for step in range(300):
    hypothesis = W * X # H(x) = W * X 가설 함수
    cost = tf.reduce_mean(tf.square(hypothesis - Y)) # 에러 차이 제곱의 평균

    alpha = 0.01
    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))
    descent = W - tf.multiply(alpha, gradient)
    W.assign(descent)
    
    # 10의 배수 값마다 
    if step % 10 == 0:
        print('{:5} | {:10.4f} | {:10.6f}'.format(
            step, cost.numpy(), W.numpy()[0]))
